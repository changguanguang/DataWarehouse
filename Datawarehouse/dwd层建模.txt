1.

	--dwd层的任务
		① 对用户行为数据解析（用户行为初始都是json字符串，需要解析json，取出字段放入到hive表中）
		② 对核心数据进行过滤
		③ 对业务数据采用维度模型重新建模

	-- dwd层维度退化
		在dwd层业务数据的处理中对维度表进行退化，
		也就是把多个维度表合并为一个维度表，这样
		将表减少，从而减少join操作（join操作在数仓中
		十分费时）。
			这里将mysql中的数据导入到hive表中，没有了
			主键的定义，也没有范式的要求，所以可以进行
			合并，有利于自己的后续计算操作。
		比如： 将商品sku表，spu表，商品分类表（1，2，3级）合并为一个商品大表

2. 在ods层，数据都是以lzo形式存储在hdfs中，
	然而在dwd层，数据都是以parquet形式存储在hdfs中

3. dwd层，优惠卷使用表--累积性快照事实表
		-- 生命周期： get - using - used
		-- 在ods层，优惠卷使用表中的每个分区包含在这个时间点使用过优惠卷的记录（包括get，using，和used）
		然而在dwd层，优惠卷使用事实表中的每个分区以get_time作为分区标准，即每个分区中数据都是get_time=dt的数据
		
		-- 在实现过程中，old表 与 new表进行全外连接（full outer join）。
			在join之后，将两表的数据去除空值后合并。（判断是否为空）
		-- 分区字段是 dt，在hive表中，分区字段是在表中是一个字段，在hdfs实际存储中，是一个分区名称（文件夹名称）
			这里使用动态分区
			--动态分区：在insert的时候不会指定具体是那个分区，而是直接指定表中的字段 dt的值，从而自动分区
						达到根据表的数据自动动态分区的效果。
4. 拉链表：
	--为什么要使用拉链表？
		拉链表适用于：数据会发生变化，但是大部分是不变的（缓慢变化维）
		比如：用户信息会发生变化，但是每天变化的比例不高。
				如果数据量有一定的规模，按照每日全量的方式保存效率很低，
				每日全量：全量数据导入hdfs->ods->dwd，每日全部数据在传输效率很低，
						因此采用增量以及变化导入hdfs & ods，
					
	-- 拉链表的思想：
		使用新增和变化的数据与昨天数据进行union合并，导入临时表，然后覆盖原表
		-- 为什么要用临时表覆盖？
			答：hive数仓中，数据无法更新，所以要改变数据，就用一个同样结构的临时表覆盖原表
		
5. dwd层:
	--构建星型模型
		-- 事实表 fact_info
		-- 维度退化后的维度表 dim_info
	ods层 
		是雪花模型（每个表都自己导入自己数据）
		
		